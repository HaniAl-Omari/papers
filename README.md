# Paper notes

Notes from papers I'm reading, ordered chronologically.

1. Conditional Random Fields: probabilistic models for segmenting and labeling sequence data, Lafferty et al, 2001 [[Paper](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)] [[Notes](0106.md)] [\#nlp](#nlp) [\#architectures](#architectures)
2. Introduction to the CoNLL-2003 shared task: language-independent named entity recognition, Sang et al., 2003 [[Paper](https://dl.acm.org/citation.cfm?id=1119195)] [[Notes](0306.md)] [\#nlp](#nlp) [\#datasets](#datasets)
3. Bidirectional LSTM-CRF Models for sequence tagging, Huang et al., 2015 [[Paper](https://arxiv.org/abs/1508.01991)] [[Notes](1508.01991.md)] [\#nlp](#nlp) [\#architectures](#architectures)
4. Named Entity Recognition with Bidirectional LSTM-CNNs, Chiu et al., 2016 [[Paper](https://www.aclweb.org/anthology/Q16-1026)] [[Notes](1607).md)] [\#nlp](#nlp) [\#architectures](#architectures)
5. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [[Paper](https://arxiv.org/abs/1705.00108)] [[Notes](1705.00108.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
6. Attention is all you need, Vaswani et al., 2018 [[Paper](https://arxiv.org/abs/1706.03762)] [[Notes](1706.03762.md)] [\#nlp](#nlp) [\#architectures](#architectures)
7. Deep contextualized word representations, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1802.05365)] [[Notes](1802.05365.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
8. Dissecting contextual word embeddings: architecture and representation, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1808.08949)] [[Notes](1808.08949.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
9. Contextual string embeddings for sequence labeling, Akbik et al., 2018 [[Paper](https://alanakbik.github.io/papers/coling2018.pdf)] [[Notes](1808.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
10. BERT: Pre-training of deep bidirectional transformers for language understanding, Devlin et al., 2018 [[Paper](https://arxiv.org/abs/1810.04805)] [[Notes](1810.04805.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
11. Flair: an easy-to-use framework for stat-of-the-art NLP [[Paper](https://www.aclweb.org/anthology/N19-4010)] [[Notes](1906.md)] [\#nlp](#nlp) [\#frameworks](#frameworks)
12. XLNet: generalized autoregressive pretraining for language understanding, Yang et al., 2019 [[Paper](https://arxiv.org/abs/1906.08237)] [[Notes](1906.08237.md)] [\#nlp](#nlp) [\#architectures](#architectures)
13. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [[Paper](https://arxiv.org/abs/1907.05572)] [[Notes](1907.05572.md)] [\#nlp](#nlp) [\#architectures](#architectures)

## Tags

### NLP

1. Conditional Random Fields: probabilistic models for segmenting and labeling sequence data, Lafferty et al, 2001 [[Paper](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)] [[Notes](0106.md)] [\#nlp](#nlp) [\#architectures](#architectures)
2. Introduction to the CoNLL-2003 shared task: language-independent named entity recognition, Sang et al., 2003 [[Paper](https://dl.acm.org/citation.cfm?id=1119195)] [[Notes](0306.md)] [\#nlp](#nlp) [\#datasets](#datasets)
3. Bidirectional LSTM-CRF Models for sequence tagging, Huang et al., 2015 [[Paper](https://arxiv.org/abs/1508.01991)] [[Notes](1508.01991.md)] [\#nlp](#nlp) [\#architectures](#architectures)
4. Named Entity Recognition with Bidirectional LSTM-CNNs, Chiu et al., 2016 [[Paper](https://www.aclweb.org/anthology/Q16-1026)] [[Notes](1607).md)] [\#nlp](#nlp) [\#architectures](#architectures)
5. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [[Paper](https://arxiv.org/abs/1705.00108)] [[Notes](1705.00108.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
6. Attention is all you need, Vaswani et al., 2018 [[Paper](https://arxiv.org/abs/1706.03762)] [[Notes](1706.03762.md)] [\#nlp](#nlp) [\#architectures](#architectures)
7. Deep contextualized word representations, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1802.05365)] [[Notes](1802.05365.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
8. Dissecting contextual word embeddings: architecture and representation, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1808.08949)] [[Notes](1808.08949.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
9. Contextual string embeddings for sequence labeling, Akbik et al., 2018 [[Paper](https://alanakbik.github.io/papers/coling2018.pdf)] [[Notes](1808.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
10. BERT: Pre-training of deep bidirectional transformers for language understanding, Devlin et al., 2018 [[Paper](https://arxiv.org/abs/1810.04805)] [[Notes](1810.04805.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
11. Flair: an easy-to-use framework for stat-of-the-art NLP [[Paper](https://www.aclweb.org/anthology/N19-4010)] [[Notes](1906.md)] [\#nlp](#nlp) [\#embeddings](#frameworks)
12. XLNet: generalized autoregressive pretraining for language understanding, Yang et al., 2019 [[Paper](https://arxiv.org/abs/1906.08237)] [[Notes](1906.08237.md)] [\#nlp](#nlp) [\#architectures](#architectures)
13. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [[Paper](https://arxiv.org/abs/1907.05572)] [[Notes](1907.05572.md)] [\#nlp](#nlp) [\#architectures](#architectures)

### Embeddings

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [[Paper](https://arxiv.org/abs/1705.00108)] [[Notes](1705.00108.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
2. Deep contextualized word representations, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1802.05365)] [[Notes](1802.05365.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
3. Dissecting contextual word embeddings: architecture and representation, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1808.08949)] [[Notes](1808.08949.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
4. BERT: Pre-training of deep bidirectional transformers for language understanding, Devlin et al., 2018 [[Paper](https://arxiv.org/abs/1810.04805)] [[Notes](1810.04805.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)

### Architectures

1. Conditional Random Fields: probabilistic models for segmenting and labeling sequence data, Lafferty et al, 2001 [[Paper](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)] [[Notes](0106.md)] [\#nlp](#nlp) [\#architectures](#architectures)
2. Bidirectional LSTM-CRF Models for sequence tagging, Huang et al., 2015 [[Paper](https://arxiv.org/abs/1508.01991)] [[Notes](1508.01991.md)] [\#nlp](#nlp) [\#architectures](#architectures)
3. Named Entity Recognition with Bidirectional LSTM-CNNs, Chiu et al., 2016 [[Paper](https://www.aclweb.org/anthology/16-1026)] [[Notes](1607).md)] [\#nlp](#nlp) [\#architectures](#architectures)
4. Attention is all you need, Vaswani et al., 2018 [[Paper](https://arxiv.org/abs/1706.03762)] [[Notes](1706.03762.md)] [\#nlp](#nlp) [\#architectures](#architectures)
5. XLNet: generalized autoregressive pretraining for language understanding, Yang et al., 2019 [[Paper](https://arxiv.org/abs/1906.08237)] [[Notes](1906.08237.md)] [\#nlp](#nlp) [\#architectures](#architectures)
6. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [[Paper](https://arxiv.org/abs/1907.05572)] [[Notes](1907.05572.md)] [\#nlp](#nlp) [\#architectures](#architectures)

### Frameworks

1. Flair: an easy-to-use framework for stat-of-the-art NLP [[Paper](https://www.aclweb.org/anthology/N19-4010)] [[Notes](1906.md)] [\#nlp](#nlp) [\#frameworks](#frameworks)

### Datasets

1. Introduction to the CoNLL-2003 shared task: language-independent named entity recognition, Sang et al., 2003 [[Paper](https://dl.acm.org/citation.cfm?id=1119195)] [[Notes](0306.md)] [\#nlp](#nlp) [\#datasets](#datasets)
