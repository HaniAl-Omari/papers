# Paper notes

Notes from papers I'm reading, mostly NLP

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [\#nlp](#nlp) [\#embeddings](#embeddings)
   * [Paper](https://arxiv.org/abs/1705.00108)
   * [Notes](1705.00108.md)
2. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [\#nlp](#nlp) [\#architectures](#architectures)
    * [Paper](https://arxiv.org/abs/1907.05572)
    * [Notes](1907.05572.md)

## NLP

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [\#nlp](#nlp) [\#embeddings](#embeddings)
   * [Paper](https://arxiv.org/abs/1705.00108)
   * [Notes](1705.00108.md)
2. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [\#nlp](#nlp) [\#architectures](#architectures)
    * [Paper](https://arxiv.org/abs/1907.05572)
    * [Notes](1907.05572.md)

## Embeddings

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [\#nlp](#nlp) [\#embeddings](#embeddings)
   * [Paper](https://arxiv.org/abs/1705.00108)
   * [Notes](1705.00108.md)

## Architectures

1. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [\#nlp](#nlp) [\#architectures](#architectures)
    * [Paper](https://arxiv.org/abs/1907.05572)
    * [Notes](1907.05572.md)
