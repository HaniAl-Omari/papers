# Paper notes

Notes from papers I'm reading, mostly NLP

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [[Paper](https://arxiv.org/abs/1705.00108)] [[Notes](1705.00108.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
2. Deep contextualized word representations, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1802.05365)] [[Notes](1802.05365.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
3. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [[Paper](https://arxiv.org/abs/1907.05572)] [[Notes](1907.05572.md)] [\#nlp](#nlp) [\#architectures](#architectures)

## Tags

### NLP

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [[Paper](https://arxiv.org/abs/1705.00108)] [[Notes](1705.00108.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
2. Deep contextualized word representations, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1802.05365)] [[Notes](1802.05365.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
3. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [[Paper](https://arxiv.org/abs/1907.05572)] [[Notes](1907.05572.md)] [\#nlp](#nlp) [\#architectures](#architectures)

### Embeddings

1. Semi-supervised sequence tagging with bidirectional language models, Peters et al., 2017 [[Paper](https://arxiv.org/abs/1705.00108)] [[Notes](1705.00108.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)
2. Deep contextualized word representations, Peters et al., 2018 [[Paper](https://arxiv.org/abs/1802.05365)] [[Notes](1802.05365.md)] [\#nlp](#nlp) [\#embeddings](#embeddings)

### Architectures

1. R-Transformer: Recurrent Neural Network Enhanced Transformer, Wang et al., 2019 [[Paper](https://arxiv.org/abs/1907.05572)] [[Notes](1907.05572.md)] [\#nlp](#nlp) [\#architectures](#architectures)
