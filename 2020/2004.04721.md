# Translation artifacts in cross-lingual transfer learning, Artetxe et al., 2020

## [Paper](https://arxiv.org/abs/2004.04721), [Code](https://github.com/artetxem/esxnli) Tags: \#nlp, \#machine-translation

Using MT to translate either the test set or the training set is a widely used transfer technique. In this paper, we show that such translation process can introduce subtle artifacts that have a notable impact in existing cross-lingual models.

Our findings:

* The cross-lingual transfer gap on XNLI was overestimated
* Overcoming the cross-lingual gap is not what makes translate-train wordk
* Improvements previously attributed to data augmentation should be considered
* The potential of translate-test was underestimated
* Further evaluation should better account for translation artifacts.
