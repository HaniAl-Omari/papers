# A deep learning framework for neuroscience, Richard et al., 2019

## [Paper](https://www.nature.com/articles/s41593-019-0520-2), [PDF](https://www.imbb.forth.gr/news/301019_Poirazi_DLPerspective.pdf). Tags: \#neuroscience

In artificial NNs, the three components specified by design are the objective functions, learning rules and the architecture. Here we argue that a greater focus on these components can also benefit systems neuroscience.

In this framework, a researcher observes neural activity, develops a theory of what individual neurons compute, then assembles a circuit-level theory of how the neurons combine their operations.

In large neural circuits like the neocortex or hippocampus, researches often find neurons with response properties that are difficult to summarize in a succint manner.

This paper proposes a deep learning-inspired framework for systems neuroscience.

Progress in AI in the early 21st century has been in the AI set, tasks that animals can perform effortlessly, such as perception, control long-term prediction, reasoning, planning.

Learning is easier when we have prior knowledge about the kind of problems we need to solve. Inductive bias is a way of embedding such prior knowledge into an optimization system. They might be generic (hierarchy) or specific (convolutions). Examples:

* Simple explanations: Occam's razor. Can be used in NNs with sparse representations
* Object permanence: the world is organized into objects, which are spatiotemporally constant. We can build this into ANNs by assuming consistent movement in sensory space
* Visual translation invariance: a visual feature tends to have the same meaning regardless of its location --> convolution
* Focused attention: some aspects of the information are more important than others --> attention

Current DL approaches work so well because they use the appropriate inductive biases of the AI set.

By focusing on the Brain Set for specific species, tasks that are important for survival and reproduction for that species, researchers can focus on the features most likely to be key to learning.

Many species, especially humans, develop slowly with large quantities of experiential data. Deep networks can work well in low-data regimes if they have good inductive biases.

## The three core components of a deep learning framework for the brain

### 1. Objective functions

Describes the goals of the learning system, functions of the synaptic weights of a NN and the data it receives, but they can be defined without making reference to a specific task or dataset. Cross-entropy objective function for example.

### 2. Learning rules

Describe how the parameters in a model are updated. In ANNs, these are generally used to improve on the objective function.

### 3. Architectures

Describe how the units in an ANN are arranged and what operations they can perform.

--------------------------------

Most AI researchers focus on these 3 things rather than designing specific computations. This appears to be the most tractable way to solve real-world problems.

We claim that we could explain the emergence of neural responses within a compact framework. Should the environment/data that an animal encounters be a fourth essential component for neuroscience? The core issue we are addressing in this Perspective is how to develop models of complex, hierarchical brain circuits, so we view the environment as a crucial consideration to anchor the core components, but not as one of the components itself.

Many neuroscientists recognize the importance of learning rules and architecture. But identifying the objective functions that have shaped the brain, either during learning or evolution, is less common. Unlike architectures and learning rules, objective functions may not be directly observable in the brain. But we can still define them mathematically and without making reference to a specific environment or task.

as with ANNs, the architectures, learning rules and objective functions of the brain are likely relatively simple and compact, at least in comparison to the list of computations performed by individual neurons.

One may argue that a focus on architectures, learning rules and objective functions, combined with a move away from studying the coding properties of neurons, loses much of what we have learned so far, such as orientation selectivity, frequency tuning and spatial tuning (place cells, grid cells).

Another common objection to the relevance of deep learning for neuroscience is that many behaviors that animals engage in appear to require relatively little learning. However, such innate behavior was indeed ‘learned’, only on evolutionary timescales. 

Finally, some researchers are concerned by the large number of parameters in deep ANNs, seeing them as a violation of Occam’s razor and merely an overfitting to data. 

Similarly, other researchers have, for good reason, pointed out the benefits of the inductive biases used by the brain. However, inductive biases are not on their own sufficient to solve complex tasks, like those contained in the AI Set or various Brain Sets. To solve these difficult problems, inductive biases must be paired with learning and credit assignment.
